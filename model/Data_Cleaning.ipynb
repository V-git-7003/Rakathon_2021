{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "1. Json format data for different banks is imported serially.\n",
    "2. This data is cleaned for training\n",
    "3. Dates of News published after 15:30 pm is changed to next day\n",
    "4. News published on holidays is either accounted for the next day or next-next day\n",
    "5. Finance data is called from yahoo API for min and max dates of the news published\n",
    "6. A new feature involving just the Open-Close prices ('P/L') is created in the dataframe\n",
    "7. There are usually 3 times more data for finance than news.\n",
    "8. These finance data is reduced to only those that fall on the news date or between 1 or 2 coming days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import json\n",
    "import pprint\n",
    "import datetime\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import defaultdict\n",
    "#from datetime import timedelta  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening and loading json files for each bank separately and then saving their respective cleaned csv files\n",
    "with open('State.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': ['Banking sector during the week saw more of disappointing news of '\n",
      "             'job cuts, bad loans and NPA divergences raising questions on '\n",
      "             'bank auditors.',\n",
      "             'But starting with some positive news for the weekend, loan '\n",
      "             'borrowers would be happy to note that ',\n",
      "             '\\xa0 (SBI) cut its interest rates on ',\n",
      "             '. This was announced a day after it cut marginal cost-based '\n",
      "             'lending rates (MCLR), its ',\n",
      "             ' and also slashed retail term deposit rates by 25 basis points.',\n",
      "             'Additionally, it also tied-up with World Bank to ',\n",
      "             '.',\n",
      "             'On to some less happy news, non-performing asset (NPA) '\n",
      "             'divergences in private sector banks raised ',\n",
      "             '. This comes at a time when doing business in India is getting '\n",
      "             'easier while banks disclose divergences in NPA classification '\n",
      "             'for the second time in a row in FY17.',\n",
      "             'Private sector banks including ',\n",
      "             ', ',\n",
      "             ' and ',\n",
      "             ' reported cumulative divergences of Rs 12,000 crore after the '\n",
      "             'Reserve Bank of India asked to make disclosures in classifying '\n",
      "             'select accounts as NPAs as per its inspection, which earlier '\n",
      "             'were not classified by the bank.',\n",
      "             'India’s biggest private sector lender, ',\n",
      "             ', reduced its ',\n",
      "             'in the three months period from July to September this year.',\n",
      "             'As per the latest numbers, the bank had 83,058 employees as of '\n",
      "             'September 30. This number as on June 2017 stood at 84,140 '\n",
      "             'employees.',\n",
      "             'In another break-up, one of the largest potential marriages in '\n",
      "             'the financial sector, ',\n",
      "             'and Shriram Group ',\n",
      "             '.',\n",
      "             'A USD 12-billion mega merger deal that could have created a '\n",
      "             'financial conglomerate with a universal bank with an ability to '\n",
      "             'provide a range of financial products from insurance to vehicle '\n",
      "             'finance.',\n",
      "             \"Nevertheless, Shriram Group's Founder R Thyagarajan said that \"\n",
      "             'the company ',\n",
      "             ' with IDFC even when the exclusivity agreement ends on November '\n",
      "             '8.',\n",
      "             ', promoter of Ujjivan small finance bank and erstwhile '\n",
      "             'microfinance institution, which suffered due to demonetisation '\n",
      "             'on cash collections from its borrowers, narrowed its losses to '\n",
      "             'Rs 11.95 crore and aims to turn around by the end of the year. '\n",
      "             'This would be with the help of ',\n",
      "             ' and being more aggressive on the affordable housing and small '\n",
      "             'and medium enterprise funding.',\n",
      "             'Posting second quarter financial results, public sector banks '\n",
      "             'such as ',\n",
      "             ',',\n",
      "             'and ',\n",
      "             ' posted weak profitability and poor asset quality numbers. On '\n",
      "             'the other hand, ',\n",
      "             ' reported strong numbers with improvement in non-performing '\n",
      "             'assets.',\n",
      "             ' of Rs 197.8 crore, ',\n",
      "             ' of Rs 1,530.72 crore on upfront provisions in the second '\n",
      "             'quarter while ',\n",
      "             ' in July to September to Rs 623 crore. All on account of rise in '\n",
      "             'bad loans.'],\n",
      " 'date': 'November 04, 2017',\n",
      " 'time': ' / 01:11 PM IST ',\n",
      " 'title': 'Banking sector this week: ICICI Bank cuts headcount, NPA '\n",
      "          'divergences raise questions; PSBs report more bad loans'}\n"
     ]
    }
   ],
   "source": [
    "# how the data looks now:\n",
    "pprint.pprint(data['State'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008\n"
     ]
    }
   ],
   "source": [
    "# date parser\n",
    "count=0\n",
    "for i in data['State'][:]:\n",
    "    #pprint.pprint(i['date'].strip())\n",
    "    try:\n",
    "        i['date']=datetime.datetime.strptime(i['date'].strip(), '%B %d, %Y').date()\n",
    "        count+=1  \n",
    "        #print(i['date'])\n",
    "        #print(type(i['date']))\n",
    "    except ValueError as e:\n",
    "        print('ValueError:', e,'with date',i['date'])\n",
    "        # pprint.pprint(i['date'][0:5])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "for i in data['State'][:1]:\n",
    "    print(type(i['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexError: list index out of range with time                                                                   \n",
      "IndexError: list index out of range with time                                                                   \n",
      "1006\n"
     ]
    }
   ],
   "source": [
    "# time parser\n",
    "# changes the news date to the next day for news after 15:30 pm\n",
    "count = 0\n",
    "for i in data['State'][:]:\n",
    "    \n",
    "    try:\n",
    "        i['time'] = i['time'].strip().split()[1]+' '+i['time'].strip().split()[2] # changes time in the format 7;30 pm \n",
    "        i['time'] = datetime.datetime.strptime(i['time'],'%I:%M %p').time()\n",
    "        \n",
    "        if i['time'] > datetime.datetime.strptime('15:30','%H:%M').time():\n",
    "            #print('before date',i['date'])\n",
    "            i['date']=i['date']+datetime.timedelta(days=1)\n",
    "            #print('after date',i['date'])\n",
    "        count+=1\n",
    "       \n",
    "    except (ValueError,IndexError) as e:\n",
    "        print('IndexError:', e,'with time',i['time'])\n",
    "print(count)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(news):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all special characters like \"\\u00a0\" \n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [word for word in news if word not in string.punctuation]\n",
    "      \n",
    "    #nopunc = [word for word in news if word not in [\"\\u00a0\"] ]\n",
    "    \n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "   # print(nopunc)\n",
    "\n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content parser\n",
    "# cleans the content\n",
    "for i in data['State'][0:]:\n",
    "    try:\n",
    "        i['content']=text_process(i['content'])\n",
    "        #print(text)\n",
    "            \n",
    "    except:\n",
    "        print('\\n*3 The error causing content',i['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 11:20:00\n",
      "\n",
      " 2017-06-25\n",
      "\n",
      " [',', 'one', \"world's\", '50', 'largest', 'banks,', 'pays', 'small', 'fraction', 'top', 'management', 'compared', 'private', 'sector', 'players', 'like', 'Former', 'RBI', 'governor', 'Raghuram', 'Rajan', 'flagged', 'low', 'remuneration', 'issue', 'last', 'August', 'saying', 'makes', 'difficult', 'state-owned', 'banks', '\"attract', 'top', 'talent,', 'especially', 'lateral', 'entry\".According', 'annual', 'reports', 'various', 'banks,', 'SBI', 'chairman', 'Arundhati', 'Bhattacharya', 'took', 'home', 'Rs', '28.96', 'lakh', 'last', 'fiscal,', 'pittance', 'compared', 'remuneration', 'counterparts', 'private', 'banks', 'receive.In', 'comparision,', 'ICICI', 'Bank', 'MD', 'CEO', 'Chanda', 'Kochhar', 'received', 'basic', 'salary', 'Rs', '2.66', 'crore', 'last', 'fiscal', 'besides', 'Rs', '2.2', 'crore', 'performance', 'bonus.', 'addition,', 'received', 'allowances', 'perquisites', 'Rs', '2.43', 'crore.Similarly,', 'Shikha', 'Sharma,', 'MD', 'CEO', 'Axis', 'Bank,', 'took', 'home', 'basic', 'salary', 'Rs', '2.7', 'crore', 'Rs', '1.35', 'crore', 'variable', 'pay,', 'besides', 'host', 'perk', 'allowances,', 'like', 'Rs', '90', 'lakh', 'HRA.Yes', 'Bank', 'MD', 'CEO', 'Rana', 'Kapoor,', 'also', 'happens', 'promoter', 'bank,', 'took', 'home', 'Rs', '6.8', 'crore', 'salary', '2016-17.HDFC', \"Bank's\", 'Managing', 'Director', 'Aditya', 'Puri', 'saw', 'remuneration', 'rise', 'marginally', 'Rs', '10', 'crore', 'exercised', 'stock', 'options', 'worth', 'Rs', '57', 'crore', 'last', 'fiscal.Speaking', 'public', 'sector', 'banks', 'banking', 'conference', 'Mumbai,', 'Rajan', 'said', 'state-owned', 'banks', 'tended', 'overpay', 'bottom', 'underpay', 'top', 'executives.He', 'jokingly', 'said', 'underpaid', 'disparity', 'made', 'harder', 'attract', 'talent', 'outside', 'top', 'level', 'public', 'sector', 'banks.On', 'business', 'front,', 'SBI,', 'merger', 'subsidiary', 'banks,', 'caters', '42.04', 'crore', 'customers', 'market', 'share', '23.07', 'per', 'cent', '21.16', 'per', 'cent', 'deposits', 'advances,', 'opposed', '18.05', 'per', 'cent', '17.02', 'per', 'cent', 'respectively,', 'merger.The', 'nearest', 'rival', 'SBI,', 'post', 'merger,', 'market', 'share', '5.96', 'per', 'cent', '7.04', 'per', 'cent', 'deposits', 'advances', 'respectively.Remuneration', 'comprises', 'various', 'components', 'including', 'basic', 'salary,', 'allowances', 'perquisite,', 'PF,', 'superannuation', 'allowances,', 'gratuity', 'performance', 'bonus', 'payment', 'performance', 'bonus', 'deferred', 'multi-year', 'period.']\n",
      "\n",
      " 12:28:00\n",
      "\n",
      " 2017-06-27\n",
      "\n",
      " ['rally', 'PSU', 'banking', 'stocks', 'last', 'one', 'year', 'largely', 'hopes', 'reforms', 'central', 'bank', 'reduce', 'stress', 'non-performing', 'assets', '(NPA).', 'But,', 'soon', 'Reserve', 'Bank', 'India', '(RBI)', 'announced', 'measure', 'bring', 'NPA,', 'index', 'slipped', '3', 'percent', 'since', 'then.The', 'Nifty', 'PSU', 'index', 'rallied', '20', 'percent', 'last', 'one', 'year', 'led', 'gains', 'Canara', 'Bank', '(up', '52', 'percent),', 'followed', '(up', '32', 'percent),', '(up', '32.4', 'percent),', '(up', '29', 'percent),', '(up', '14', 'percent)', 'etc.', 'among', 'others.Investors', 'pumped', 'money', 'PSU', 'banks', 'despite', 'knowing', 'challenges', 'sector', 'face,', 'especially', 'PSU', 'banks', 'exposure', '70', 'percent', 'stressed', 'assets.The', 'strong', 'steps', 'taken', 'Reserve', 'Bank', 'resolve', 'NPAs', 'likely', 'raise', 'provisioning', 'whopping', '25', 'percent', 'year', 'lenders', 'take', '60', 'percent', 'haircut', 'resolving', 'accounts.\"Based', 'assessment', 'embedded', 'value', 'top', '50', 'NPA', 'cases,', 'estimate', '60', 'percent', 'haircut', 'would', 'needed', 'loan', 'assets.', 'would', 'mean', 'banks', 'increase', 'provisioning', 'another', '25', 'percent', 'fiscal,', 'compared', 'nine', 'percent', 'last', 'fiscal,\"', 'Crisil', 'senior', 'director', 'Krishnan', 'Sitaraman', 'said.The', 'RBI', 'fortnight', 'back', 'referred', '12', 'largest', 'bad', 'loans', 'resolution', 'Insolvency', 'Bankruptcy', 'Code', '2016', '(IBC),', 'provides', 'companies', 'referred', 'liquidation.The', 'apex', 'bank', 'took', 'decision', 'based', 'recommendations', 'internal', 'advisory', 'committee', '(IAC)', 'also', 'mandated', 'time-bound', 'resolution', 'cases.The', 'largest', '12', 'accounts', 'RBI', 'named', '-', '(Rs', '44,478', 'crore),', '(Rs', '44,365', 'crore),', '(Rs', '37,284', 'crore),', 'Bhushan', 'Power', '(Rs', '37248', 'crore),', '(Rs', '22,075', 'crore),', '(Rs', '14,075', 'crore),', '(Rs', '12,115', 'crore)', '(Rs', '10,274', 'crore),', '(Rs', '10,065', 'crore)', '(Rs', '9,635', 'crore),', '(Rs', '6,953', 'crore)', '(Rs', '5,165', 'crore).“PSU', 'Banks', 'facing', 'challenging', 'times.', 'exception', 'couple', 'them,', 'stopped', 'growing', 'advances', 'book', 'owing', 'legacy', 'NPAs', 'insufficient', 'capital', 'adequacy.', 'banking', 'sector', 'saddled', 'NPAs', 'Rs', '8', 'lakh', 'crore,', 'Rs', '6', 'lakh', 'crore', 'PSU', 'banks,”', 'Dhiraj', 'Relli,', 'MD', '&', 'CEO,', 'HDFC', 'Securities', 'told', 'Moneycontrol.“The', 'resolution', 'non-performing', 'loans', 'likely', 'require', 'significant', 'haircuts', 're-priced', 'loans', 'attract', 'attention', 'private', 'investors', 'asset', 'reconstruction', 'companies,”', 'said.Relli', 'added', 'provision', 'coverage', 'ratio', 'system', 'rise', '37-43', 'percent', 'stressed', 'loans', '55-60', 'percent', 'post', 'reference', 'Insolvency', 'Bankruptcy', 'Code', 'unless', 'RBI', 'comes', 'fresh', 'provisioning', 'norms', 'cases', 'give', 'relief', 'lenders.Vinod', 'Nair,', 'Head', 'Research,', 'Geojit', 'Financial', 'Services', 'said', 'near', 'term', 'cautious', 'view', 'broad', 'PSU', 'banks.“Recently,', 'PSU', 'Banks', 'moved', 'limelight', 'due', 'high', 'expectation', 'quicker', 'resolution', 'NPA', 'issue', 'mergers', '&', 'consolidations.', 'PSU', 'banks', 'continue', 'grapple', 'muted', 'loan', 'growth', 'significant', 'improvement', 'outlook,”', 'said.']\n",
      "\n",
      " 18:29:00\n",
      "\n",
      " 2017-07-14\n",
      "\n",
      " ['Thursday', 'reduced', 'National', 'Electronic', 'Funds', 'Transfer', '(NEFT)', 'Real', 'Time', 'Gross', 'Settlement', '(RTGS)', 'charges', '75', 'percent.', 'reduced', 'charges', 'applicable', 'internet', 'banking', 'transactions', 'mobile', 'banking', 'transactions.The', 'new', 'charges', 'effective', 'July', '15', '(Saturday),', 'bank', 'said', 'official', 'statement.On', 'Wednesday,', 'bank', 'transactions', 'Rs', '1000,', 'effective', 'July', '1.The', 'bank', 'expects', 'reduction', 'charges', 'push', 'customers', 'towards', 'digital', 'transactions', 'boost', 'government’s', 'Digital', 'India', 'initiative.', 'India’s', 'largest', 'public', 'sector', 'bank', '3.27', 'crore', 'internet', 'banking', 'customers', 'nearly', '2', 'crore', 'mobile', 'banking', 'customers', 'March', '31,', '2017.“Digitalization', 'excellence', 'operations', 'one', 'core', 'strategies', 'providing', 'convenience', 'customers,\"', 'said', 'Rajnish', 'Kumar,', 'Managing', 'Director', '–', 'NBG,', 'SBI.']\n"
     ]
    }
   ],
   "source": [
    "## check to see how the data looks!\n",
    "for i in data['State'][0:3]:\n",
    "    print('\\n',i['time'])\n",
    "    print('\\n',i['date'])\n",
    "    print('\\n',i['content'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645\n"
     ]
    }
   ],
   "source": [
    "# converting data to dictionary with key as date and value as news\n",
    "news_dictionary=defaultdict(list)\n",
    "\n",
    "for i in data['State'][:]:\n",
    "    news_dictionary[i['date']].extend(i['content'])\n",
    "\n",
    "print(len(news_dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(news_dictionary[datetime.date(2015, 11, 13)])\\n\\nempty_keys=[datetime.date(2015, 11, 13),\\n datetime.date(2015, 9, 25),\\n datetime.date(2015, 8, 3),\\n datetime.date(2017, 3, 17),\\n datetime.date(2017, 3, 31),\\n datetime.date(2017, 3, 30),\\n datetime.date(2017, 7, 24),\\n datetime.date(2017, 5, 31),\\n datetime.date(2017, 6, 20),\\n datetime.date(2017, 6, 23)]\\n\\nfor i in empty_keys:\\n    news_dictionary.pop(i)\\n  \\n#len(news_dictionary[datetime.date(2017, 5, 31)])\\n'"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference cell for empty dates\n",
    "\"\"\"\n",
    "print(news_dictionary[datetime.date(2015, 11, 13)])\n",
    "\n",
    "empty_keys=[datetime.date(2015, 11, 13),\n",
    " datetime.date(2015, 9, 25),\n",
    " datetime.date(2015, 8, 3),\n",
    " datetime.date(2017, 3, 17),\n",
    " datetime.date(2017, 3, 31),\n",
    " datetime.date(2017, 3, 30),\n",
    " datetime.date(2017, 7, 24),\n",
    " datetime.date(2017, 5, 31),\n",
    " datetime.date(2017, 6, 20),\n",
    " datetime.date(2017, 6, 23)]\n",
    "\n",
    "for i in empty_keys:\n",
    "    news_dictionary.pop(i)\n",
    "  \n",
    "#len(news_dictionary[datetime.date(2017, 5, 31)])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getting input values for the yahoo api\n",
    "k=news_dictionary.keys()\n",
    "max_date=max(k)\n",
    "min_date=min(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Financial data:\n",
    "import pandas_datareader.data as web   # Package and modules for importing data; this code may change depending on pandas version\n",
    "import datetime\n",
    " \n",
    "# We will look at stock prices over these dates\n",
    "start = min_date\n",
    "end =  max_date\n",
    "bank_name = 'StateBANK.NS' \n",
    "\n",
    "bank_fin = web.DataReader(\"SBIN.NS\", \"yahoo\", start, end)\n",
    " \n",
    "type(bank_fin)\n",
    "#bank_fin[datetime.date(2019,1,4)]\n",
    "#bank_fin.reset_index(inplace=True)\n",
    "#bank_fin[bank_fin['Date']=='2019-01-14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087\n"
     ]
    }
   ],
   "source": [
    "#Bank data as df\n",
    "bank_fin.head()\n",
    "bank_fin['P/L']=bank_fin['Close']-bank_fin['Open']\n",
    "bank_fin.reset_index(inplace=True)\n",
    "print(len(bank_fin['P/L'].values))# number of P/L values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing for the next cell\n",
    "news_date_list = list(news_dictionary.keys())\n",
    "bank_date_list = list(bank_fin['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-08-21 : 1.2299957275390625\n",
      "2012-08-22 : 1.214996337890625\n",
      "2012-08-23 : -0.220001220703125\n",
      "2012-08-24 : -0.6150054931640625\n",
      "2012-08-27 : -4.5749969482421875\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "# Picking out P/L for those dates with news articles\n",
    "# This accounts for news that has in the weekends too!\n",
    "# News on sat and sun are corelated to P/L on Monday (Works for any other holidays with two days gap too)\n",
    "\n",
    "P_L_dict = {}\n",
    "test_list = []\n",
    "try:\n",
    "    for i in range(len(bank_fin['Date'])):\n",
    "        if bank_fin['Date'][i].date() in news_date_list:\n",
    "            #print(date_list[i])\n",
    "            P_L_dict[bank_fin['Date'][i].date()] = bank_fin['P/L'][i]  \n",
    "\n",
    "    for holiday_dates in news_date_list:\n",
    "        if holiday_dates not in bank_fin.values:\n",
    "            for i in range(len(bank_fin['P/L'])):\n",
    "                if holiday_dates + datetime.timedelta(days=1) == bank_fin['Date'][i]:\n",
    "                    P_L_dict[holiday_dates] = bank_fin['P/L'][i]\n",
    "                    break\n",
    "                elif holiday_dates + datetime.timedelta(days=2) == bank_fin['Date'][i]:\n",
    "                    P_L_dict[holiday_dates] = bank_fin['P/L'][i]\n",
    "                    break\n",
    "        \n",
    "except (IndexError,ValueError) as e:\n",
    "    print('This is the error',e)\n",
    "    \n",
    "\n",
    "for i in sorted(P_L_dict)[:5]:\n",
    "    print(i,':',P_L_dict[i])\n",
    "\n",
    "print(len(P_L_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is date that is causing trouble 2017-10-20\n",
      "This is date that is causing trouble 2017-09-30\n",
      "This is date that is causing trouble 2013-11-15\n",
      "This is date that is causing trouble 2013-08-09\n",
      "This is date that is causing trouble 2015-09-25\n",
      "This is date that is causing trouble 2019-03-29\n",
      "This is date that is causing trouble 2019-04-19\n",
      "This is date that is causing trouble 2020-05-01\n",
      "This is date that is causing trouble 2020-10-02\n",
      "This is date that is causing trouble 2020-04-04\n",
      "This is date that is causing trouble 2020-04-10\n",
      "This is date that is causing trouble 2019-08-31\n",
      "This is date that is causing trouble 2019-10-19\n",
      "This is date that is causing trouble 2019-10-26\n",
      "This is date that is causing trouble 2019-08-10\n",
      "   label                                               news\n",
      "0    0.0  [,, one, world's, 50, largest, banks,, pays, s...\n",
      "1    0.0  [rally, PSU, banking, stocks, last, one, year,...\n",
      "2    1.0  [Thursday, reduced, National, Electronic, Fund...\n",
      "3    1.0  [Sharmila, Joshi, Sharmilajoshi.com, told, CNB...\n",
      "4    0.0  [markets, created, fresh, all-time, high, week...\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "# labeling the positive and negative news and creating DF:\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in news_dictionary:\n",
    "    try:\n",
    "        if P_L_dict[i]>=0:\n",
    "            df = df.append({'news': news_dictionary[i], 'label': int(1)}, ignore_index=True)\n",
    "                \n",
    "\n",
    "        elif P_L_dict[i]<0:\n",
    "            df = df.append({'news': news_dictionary[i], 'label': int(0)}, ignore_index=True)\n",
    "           \n",
    "            \n",
    "    except:\n",
    "        print('This is date that is causing trouble',i )\n",
    "\n",
    "print(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "247\n"
     ]
    }
   ],
   "source": [
    "# checking the consistency of length of first news after all this processing\n",
    "print(len(df['news'][0]))\n",
    "for i in news_dictionary:\n",
    "    print(len(news_dictionary[i]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645\n",
      "645\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "# checking for the consistency in number of news after all these processing\n",
    "print(len(news_dictionary))\n",
    "print(len(news_date_list))\n",
    "print(len(df)) # difference is because there are two news that does not correlate to finance even in the next two days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removing empty news finally!\n",
    "def join(news):\n",
    "    joined_news = ' '.join(news)\n",
    "    return joined_news\n",
    "\n",
    "df['news']=df['news'].apply(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               news\n",
      "0    0.0  , one world's 50 largest banks, pays small fra...\n",
      "1    0.0  rally PSU banking stocks last one year largely...\n",
      "2    1.0  Thursday reduced National Electronic Funds Tra...\n",
      "3    1.0  Sharmila Joshi Sharmilajoshi.com told CNBC-TV1...\n",
      "4    0.0  markets created fresh all-time high week gone ...\n"
     ]
    }
   ],
   "source": [
    "df['news'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset= [\"news\"],inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 598 entries, 0 to 629\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   598 non-null    float64\n",
      " 1   news    598 non-null    object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the file:\n",
    "df.to_csv('State.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               news\n",
      "0    0.0  , one world's 50 largest banks, pays small fra...\n",
      "1    0.0  rally PSU banking stocks last one year largely...\n",
      "2    1.0  Thursday reduced National Electronic Funds Tra...\n",
      "3    1.0  Sharmila Joshi Sharmilajoshi.com told CNBC-TV1...\n",
      "4    0.0  markets created fresh all-time high week gone ...\n"
     ]
    }
   ],
   "source": [
    "# checking the loading of data:\n",
    "df_loaded =pd.read_csv('State.csv')\n",
    "print(df_loaded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End!\n",
    "### The saved csv files for different banks from here imported into Model.ipynb and then concatenated,\n",
    "### which is used for building the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
