{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import json\n",
    "import pprint\n",
    "import datetime\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import defaultdict\n",
    "#from datetime import timedelta  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': ['The second largest private lender\\xa0',\n",
      "              ' on Monday launched co-branded medical benefits card with ',\n",
      "              ', which allows corporates to disburse medical allowances to '\n",
      "              'their employees and has insurance cover for accidents.',\n",
      "              'With the HDFC Bank-Apollo Medical Benefits Cards, corporates '\n",
      "              'can load the specified allowance onto the card each month, '\n",
      "              'which can be used by employees for medical expenditure '\n",
      "              'Visa/MasterCard outlets. The bank claimed that this is the '\n",
      "              'first-of-its kind product in the country.',\n",
      "              'The card comes with a free accidental death insurance of Rs 3 '\n",
      "              'lakh and accident hospitalisation insurance of Rs 30,000 apart '\n",
      "              'from discounts at Apollo network including Apollo Hospitals, '\n",
      "              'Apollo Pharmacies, Apollo Clinics and Apollo White Dental.',\n",
      "              '\"The HDFC Bank-Apollo Medical Benefits Card offers an easy and '\n",
      "              'convenient way for corporates to save costs and eliminate '\n",
      "              'administrative issues while disbursing medical allowances,\" '\n",
      "              'said Parag Rao, senior executive vice-president of the bank.'],\n",
      "  'date': 'May 18, 2015',\n",
      "  'time': ' / 07:12 PM IST ',\n",
      "  'title': 'HDFC Bk launches prepaid medical card with Apollo Hospitals'}]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data['hdfc'][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\n"
     ]
    }
   ],
   "source": [
    "# date parser\n",
    "count=0\n",
    "for i in data['hdfc'][:]:\n",
    "    #pprint.pprint(i['date'].strip())\n",
    "    try:\n",
    "        i['date']=datetime.datetime.strptime(i['date'].strip(), '%B %d, %Y').date()\n",
    "        count+=1  \n",
    "        #print(i['date'])\n",
    "        #print(type(i['date']))\n",
    "    except ValueError as e:\n",
    "        print('ValueError:', e,'with date',i['date'])\n",
    "        # pprint.pprint(i['date'][0:5])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "for i in data['hdfc'][:1]:\n",
    "    print(type(i['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexError: list index out of range with time                                                                   \n",
      "466\n"
     ]
    }
   ],
   "source": [
    "# time parser\n",
    "count = 0\n",
    "for i in data['hdfc'][:]:\n",
    "    \n",
    "    try:\n",
    "        i['time'] = i['time'].strip().split()[1]+' '+i['time'].strip().split()[2] # changes time in the format 7;30 pm \n",
    "        i['time'] = datetime.datetime.strptime(i['time'],'%I:%M %p').time()\n",
    "        \n",
    "        if i['time'] > datetime.datetime.strptime('15:30','%H:%M').time():\n",
    "            #print('before date',i['date'])\n",
    "            i['date']=i['date']+datetime.timedelta(days=1)\n",
    "            #print('after date',i['date'])\n",
    "        count+=1\n",
    "       \n",
    "    except (ValueError,IndexError) as e:\n",
    "        print('IndexError:', e,'with time',i['time'])\n",
    "print(count)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "   \n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "   # print(nopunc)\n",
    "\n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content parser\n",
    "# cleans the content\n",
    "for i in data['hdfc'][0:]:\n",
    "    try:\n",
    "        i['content']=text_process(i['content'])\n",
    "        #print(text)\n",
    "            \n",
    "    except:\n",
    "        print('\\n*3 The error causing content',i['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 19:12:00\n",
      "\n",
      " 2015-05-19\n",
      "\n",
      " ['second', 'largest', 'private', 'lender', 'Monday', 'launched', 'co-branded', 'medical', 'benefits', 'card', ',', 'allows', 'corporates', 'disburse', 'medical', 'allowances', 'employees', 'insurance', 'cover', 'accidents.With', 'HDFC', 'Bank-Apollo', 'Medical', 'Benefits', 'Cards,', 'corporates', 'load', 'specified', 'allowance', 'onto', 'card', 'month,', 'used', 'employees', 'medical', 'expenditure', 'Visa/MasterCard', 'outlets.', 'bank', 'claimed', 'first-of-its', 'kind', 'product', 'country.The', 'card', 'comes', 'free', 'accidental', 'death', 'insurance', 'Rs', '3', 'lakh', 'accident', 'hospitalisation', 'insurance', 'Rs', '30,000', 'apart', 'discounts', 'Apollo', 'network', 'including', 'Apollo', 'Hospitals,', 'Apollo', 'Pharmacies,', 'Apollo', 'Clinics', 'Apollo', 'White', 'Dental.\"The', 'HDFC', 'Bank-Apollo', 'Medical', 'Benefits', 'Card', 'offers', 'easy', 'convenient', 'way', 'corporates', 'save', 'costs', 'eliminate', 'administrative', 'issues', 'disbursing', 'medical', 'allowances,\"', 'said', 'Parag', 'Rao,', 'senior', 'executive', 'vice-president', 'bank.']\n",
      "\n",
      " 14:56:00\n",
      "\n",
      " 2015-05-26\n",
      "\n",
      " ['State-run', 'Tuesday', 'cut', 'base', 'rate', 'minimum', 'lending', 'rate', '0.25', 'percentage', 'point', '10', 'percent', ',', 'move', 'lead', 'lower', 'EMIs', 'customers.The', 'bank', 'revised', 'base', 'rate', 'lending', '10.25', 'percent', '10', 'percent', 'effect', 'June', '1,', 'Corporation', 'Bank', 'said', 'filing', 'BSE.With', 'reduction,', 'loans', 'linked', 'base', 'rates', 'become', 'cheaper', 'least', '0.25', 'percent', '.', 'month,', 'many', 'banks', 'including', ',', ',', 'reduced', 'base', 'rate', '0.25', 'percent', '10', 'percent', '.State', 'Bank', 'India,', \"country's\", 'largest', 'lender,', 'reduced', 'base', 'rate', '0.15', 'percent', '9.85', 'percent', 'effective', 'April', '10.Banks', ',', ',', 'cut', 'lending', 'rates', '0.25', 'percent', 'Reserve', 'Bank', 'India', 'Governor', 'Raghuram', \"Rajan's\", 'tough', 'talk', 'bankers', 'April', '7.The', 'RBI', 'blamed', 'banks', 'passing', 'benefits', 'two', 'repo', 'rate', 'cuts', 'borrowers', 'termed', '\"nonsense\"', \"lenders'\", 'claims', 'cost', 'funds', 'high.\"The', \"banks'\", 'marginal', 'cost', 'funding', '(has)', 'fallen,', 'notion', 'fallen,', 'non-sense.', 'fallen,\"', 'Rajan', 'said.']\n",
      "\n",
      " 14:17:00\n",
      "\n",
      " 2015-06-02\n",
      "\n",
      " ['First', 'blocks,', 'state-owned', 'Tuesday', 'cut', 'base', 'rate', 'minimum', 'lending', 'rate', '0.3', 'percent', 'within', 'hours', 'RBI', 'lowering', 'key', 'policy', 'rate', 'third', 'time', 'year.The', 'base', 'rate', 'reduced', '9.95', 'percent', '10.25', 'percent', ',', 'effective', 'June', '8,', 'Allahabad', 'Bank', 'said', 'filing', 'BSE.', 'reduction,', 'loans', 'linked', 'base', 'rate', 'come', 'least', '0.3', 'percent', '.Consequently,', 'Benchmark', 'Prime', 'Lending', 'Rate', '(BPLR)', 'bank', 'reduced', '14.20', 'percent', 'existing', '14.50', 'percent', '.The', 'rate', 'cut', 'Kolkata-based', 'lender', 'comes', 'backdrop', 'Reserve', 'Bank', 'India', 'reducing', 'repo', 'rate', '0.75', 'percent', 'since', 'January,', '2015.', 'Following', 'status', 'quo', 'RBI', 'policy', 'April,', 'many', 'lenders', 'including', ',', ',', 'reduced', 'base', 'rates.Other', 'big', 'lenders', 'Punjab', 'National', 'Bank,', 'Bank', 'Baroda,', 'IDBI', 'Bank', 'reduced', 'lending', 'rates', 'last', 'month.As', 'part', 'second', 'bi-monthly', 'monetary', 'policy', 'review', 'today,', 'RBI', 'cut', 'repo', 'rate', '(short-term', 'lending', 'rate)', '7.5', 'percent', '7.25,', 'left', 'policy', 'tools', 'like', 'cash', 'reserve', 'requirement', 'unchanged', '4', 'percent', 'Statutory', 'Liquidity', 'Ratio', '(SLR)', '21.5', 'percent', '.RBI', 'Governor', 'Raghuram', 'Rajan', 'asked', 'banks', 'follow', 'suit', 'pass', 'rate', 'cuts', '--', '0.75', 'percent', 'since', 'January', '--', 'individual', 'corporate', 'borrowers.']\n"
     ]
    }
   ],
   "source": [
    "## check to see how the data looks!\n",
    "for i in data['hdfc'][0:2]:\n",
    "    print('\\n',i['time'])\n",
    "    print('\\n',i['date'])\n",
    "    print('\\n',i['content'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting data to dictionary with key as date and value as news\n",
    "news_dictionary=defaultdict(list)\n",
    "\n",
    "for i in data['hdfc'][:]:\n",
    "    news_dictionary[i['date']].extend(i['content'])\n",
    "\n",
    "print(len(news_dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nempty_keys=[datetime.date(2015, 11, 13),\\n datetime.date(2015, 9, 25),\\n datetime.date(2015, 8, 3),\\n datetime.date(2017, 3, 17),\\n datetime.date(2017, 3, 31),\\n datetime.date(2017, 3, 30),\\n datetime.date(2017, 7, 24),\\n datetime.date(2017, 5, 31),\\n datetime.date(2017, 6, 20),\\n datetime.date(2017, 6, 23)]\\n\\nfor i in empty_keys:\\n    news_dictionary.pop(i)\\n  \\n#len(news_dictionary[datetime.date(2017, 5, 31)])\\n'"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference cell for empty dates\n",
    "\"\"\"\n",
    "print(news_dictionary[datetime.date(2015, 11, 13)])\n",
    "\n",
    "empty_keys=[datetime.date(2015, 11, 13),\n",
    " datetime.date(2015, 9, 25),\n",
    " datetime.date(2015, 8, 3),\n",
    " datetime.date(2017, 3, 17),\n",
    " datetime.date(2017, 3, 31),\n",
    " datetime.date(2017, 3, 30),\n",
    " datetime.date(2017, 7, 24),\n",
    " datetime.date(2017, 5, 31),\n",
    " datetime.date(2017, 6, 20),\n",
    " datetime.date(2017, 6, 23)]\n",
    "\n",
    "for i in empty_keys:\n",
    "    news_dictionary.pop(i)\n",
    "  \n",
    "#len(news_dictionary[datetime.date(2017, 5, 31)])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getting input values for the yahoo api\n",
    "k=news_dictionary.keys()\n",
    "max_date=max(k)\n",
    "min_date=min(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Financial data:\n",
    "import pandas_datareader.data as web   # Package and modules for importing data; this code may change depending on pandas version\n",
    "import datetime\n",
    " \n",
    "# We will look at stock prices over these dates\n",
    "start = min_date\n",
    "end =  max_date\n",
    "bank_name = 'HDFCBANK.NS' \n",
    "\n",
    "bank_fin = web.DataReader(\"HDFCBANK.NS\", \"yahoo\", start, end)\n",
    " \n",
    "type(bank_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413\n"
     ]
    }
   ],
   "source": [
    "#Bank data as df\n",
    "bank_fin.head()\n",
    "bank_fin['P/L']=bank_fin['Close']-bank_fin['Open']\n",
    "bank_fin.reset_index(inplace=True)\n",
    "print(len(bank_fin['P/L'].values))# number of P/L values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing for the next cell\n",
    "news_date_list = list(news_dictionary.keys())\n",
    "bank_date_list = list(bank_fin['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-15 : -2.4000244140625\n",
      "2015-05-19 : 0.600006103515625\n",
      "2015-05-26 : 1.47503662109375\n",
      "2015-06-02 : -14.800018310546875\n",
      "2015-06-11 : -8.699981689453125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking out P/L for those dates with news articles\n",
    "# This accounts for news that has in the weekends too!\n",
    "# News on sat and sun are corelated to P/L on Monday (Works for any other holidays with two days gap too)\n",
    "\n",
    "P_L_dict = {}\n",
    "test_list = []\n",
    "try:\n",
    "    for i in range(len(bank_fin['Date'])):\n",
    "        if bank_fin['Date'][i].date() in news_date_list:\n",
    "            #print(date_list[i])\n",
    "            P_L_dict[bank_fin['Date'][i].date()] = bank_fin['P/L'][i]  \n",
    "\n",
    "    for holiday_dates in news_date_list:\n",
    "        if holiday_dates not in bank_fin.values:\n",
    "            for i in range(len(bank_fin['P/L'])):\n",
    "                if holiday_dates + datetime.timedelta(days=1) == bank_fin['Date'][i]:\n",
    "                    P_L_dict[holiday_dates] = bank_fin['P/L'][i]\n",
    "                    break\n",
    "                elif holiday_dates + datetime.timedelta(days=2) == bank_fin['Date'][i]:\n",
    "                    P_L_dict[holiday_dates] = bank_fin['P/L'][i]\n",
    "                    break\n",
    "        \n",
    "except (IndexError,ValueError) as e:\n",
    "    print('This is the error',e)\n",
    "    \n",
    "\n",
    "for i in sorted(P_L_dict)[:5]:\n",
    "    print(i,':',P_L_dict[i])\n",
    "\n",
    "print(len(P_L_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove persistant punctuations\n",
    "def text_remove_punctuations(news):\n",
    "    \"\"\"\n",
    "    The function text_remove_punctuation:\n",
    "    1. Removes remaining commas\n",
    "    \"\"\"\n",
    "    cleaned_news = [word for word in news if word not in string.punctuation]\n",
    "    return cleaned_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# news cleaned with the extra commas! Yay!\n",
    "for v in news_dictionary:\n",
    "    news_dictionary[v] = text_remove_punctuations(news_dictionary[v])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is date that is causing trouble 2019-04-19\n",
      "This is date that is causing trouble 2020-05-01\n",
      "This is date that is causing trouble 2018-03-29\n",
      "This is date that is causing trouble 2015-09-25\n",
      "This is date that is causing trouble 2017-04-29\n",
      "   label                                               news\n",
      "0    1.0  [second, largest, private, lender, Monday, lau...\n",
      "1    1.0  [State-run, Tuesday, cut, base, rate, minimum,...\n",
      "2    0.0  [First, blocks,, state-owned, Tuesday, cut, ba...\n",
      "3    0.0  [Thursday, joined, private, sector, rivals, la...\n",
      "4    0.0  [HDFCB, reported, net, profit, INR, 46.0bn, 1Q...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labeling the positive and negative news and creating DF:\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in news_dictionary:\n",
    "    try:\n",
    "        if P_L_dict[i]>=0:\n",
    "            df = df.append({'news': news_dictionary[i], 'label': int(1)}, ignore_index=True)\n",
    "                \n",
    "\n",
    "        elif P_L_dict[i]<0:\n",
    "            df = df.append({'news': news_dictionary[i], 'label': int(0)}, ignore_index=True)\n",
    "                \n",
    "    except:\n",
    "        print('This is date that is causing trouble',i )\n",
    "\n",
    "print(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "# checking the consistency of length of first news after all this processing\n",
    "print(len(df['news'][0]))\n",
    "for i in news_dictionary:\n",
    "    print(len(news_dictionary[i]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for the consistency in number of news after all these processing\n",
    "print(len(news_dictionary))\n",
    "print(len(news_date_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[second, largest, private, lender, Monday, lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[State-run, Tuesday, cut, base, rate, minimum,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[First, blocks,, state-owned, Tuesday, cut, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[Thursday, joined, private, sector, rivals, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[HDFCB, reported, net, profit, INR, 46.0bn, 1Q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               news\n",
       "0    1.0  [second, largest, private, lender, Monday, lau...\n",
       "1    1.0  [State-run, Tuesday, cut, base, rate, minimum,...\n",
       "2    0.0  [First, blocks,, state-owned, Tuesday, cut, ba...\n",
       "3    0.0  [Thursday, joined, private, sector, rivals, la...\n",
       "4    0.0  [HDFCB, reported, net, profit, INR, 46.0bn, 1Q..."
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing empty news finally!\n",
    "df['news'].replace('', np.nan, inplace=True)\n",
    "df['news'].dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17847\n",
      "Shape of Sparse Matrix:  (324, 17847)\n",
      "Amount of Non-Zero occurences:  57988\n",
      "sparsity: 1\n"
     ]
    }
   ],
   "source": [
    "#creating a identity function to pass into countvectorizer\n",
    "def identity(news):\n",
    "    return news\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Vectorization of words, Might take awhile...\n",
    "bow_transformer = CountVectorizer(analyzer=identity).fit(df['news'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))\n",
    "\n",
    "#Tokenization or vectorization of all the generated news\n",
    "news_bow = bow_transformer.transform(df['news'])\n",
    "\n",
    "print('Shape of Sparse Matrix: ', news_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', news_bow.nnz)\n",
    "\n",
    "#calculating sparsity\n",
    "sparsity = (100.0 * news_bow.nnz / (news_bow.shape[0] * news_bow.shape[1]))\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 98 324\n"
     ]
    }
   ],
   "source": [
    "# creating train and test data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news_train, news_test, label_train, label_test = \\\n",
    "train_test_split(df['news'], df['label'], test_size=0.3)\n",
    "\n",
    "print(len(news_train), len(news_test), len(news_train) + len(news_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a pipeline of the above procedure\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=identity)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function identity at 0x7fb081569510>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(news_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "174    1.0\n",
      "242    1.0\n",
      "248    0.0\n",
      "3      0.0\n",
      "245    1.0\n",
      "108    0.0\n",
      "48     1.0\n",
      "79     1.0\n",
      "186    1.0\n",
      "302    0.0\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking the predictions\n",
    "predictions = pipeline.predict(news_test)\n",
    "print(predictions[0:10])\n",
    "print(label_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.43      0.38        37\n",
      "         1.0       0.58      0.48      0.52        61\n",
      "\n",
      "    accuracy                           0.46        98\n",
      "   macro avg       0.46      0.45      0.45        98\n",
      "weighted avg       0.49      0.46      0.47        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions,label_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
